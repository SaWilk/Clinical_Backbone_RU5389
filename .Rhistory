dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10006 & dat_adults[[project_col]] == PROJECT)] <- 30006
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10007 & dat_adults[[project_col]] == PROJECT)] <- 30007
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 40019 & dat_adults[[project_col]] == PROJECT)] <- 30019
# falsely named datasets
dat_adults[[vp_col]][which(dat_adults[[id_col]] == 227 & dat_adults[[project_col]] == PROJECT)] <- 30047
dat_adults[[vp_col]][which(dat_adults[[id_col]] == 316 & dat_adults[[project_col]] == PROJECT)] <- 30057
# Project 4
PROJECT <- 4
# assuming a 0 (or many) 0s are missing
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 4001 & dat_adults[[project_col]] == PROJECT)] <- 40001
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 4002 & dat_adults[[project_col]] == PROJECT)] <- 40002
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 4003 & dat_adults[[project_col]] == PROJECT)] <- 40003
# Project 9
PROJECT <- 9
# assuming a 0 (or many) 0s are missing
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 9901)] <- 99001
# Special Case Project 8: Remap VPIDs so children and adults have unique IDs --
dat_children_parents <- correct_child_vpids(
dat_children_parents, vpid_col = "vpid", project_col = "project", startdate_col = "startdate",
mapping_file = file.path("information", "2025-08-19_Neuzuordnung_VP-IDs_Kinder-Sample_Projekt_8.xlsx")
)
# Gather Pilot Participant IDs -------------------------------------------------
pilots_ad_auto <- find_pilot_ids(dat_general, dat_adults)
pilots_asc_auto <- find_pilot_ids(dat_general, dat_adolescents)
pilots_ch_auto <- find_pilot_ids(dat_general, dat_children_parents)
pilot_ad_2 <- c(20004)
pilot_ad_9 <- c()
pilot_ad_8 <- c(80350)
pilot_asc_7 <- c()
pilot_ch_6 <- c(62973, 62980, 62998, 62992, 62987, 62989, 62994, 62970)
pilot_ad_all <- c(pilot_ad_2, pilot_ad_9, pilot_ad_8, pilots_ad_auto)
pilot_asc_all <- c(pilots_asc_auto)
pilots_ch_all <- c(pilots_ch_auto, pilot_ch_6)
# --- SAVE P9 (and all) pilot rows BEFORE extracting them out ------------------
pilot_quest_adults  <- dplyr::filter(dat_adults, .data[[vp_col]] %in% pilot_ad_all)
# Move to separate file and from original dataset -----------------------------
dat_adults <- extract_pilot_by_vpid(
dat_adults, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilot_ad_all, sample = "adults", vpid_col = "vpid"
)
dat_adolescents <- extract_pilot_by_vpid(
dat_adolescents, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilot_asc_all, sample = "adolescents", vpid_col = "vpid"
)
dat_children_parents <- extract_pilot_by_vpid(
dat_children_parents, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilots_ch_all, sample = "children_parents", vpid_col = "vpid"
)
dat_children_p6 <- extract_pilot_by_vpid(
dat_children_p6, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilots_ch_all, sample = "children_p6", vpid_col = "VPCode"
)
dat_parents_p6 <- extract_pilot_by_vpid(
dat_parents_p6, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilots_ch_all, sample = "parents_p6", vpid_col = "VPCode"
)
# Handle duplicate IDs ---------------------------------------------------------
# Delete not needed, incomplete or faulty datasets
vp_col = "vpid"
project_col = "project"
# Project 3
del_id_ad <- c(59, 80) # Hendrik said they can be deleted as they are incomplete
dat_adults <- dat_adults %>%
dplyr::filter(!id %in% del_id_ad)
# Project 6
keep_row_id <- dat_children_parents %>%
mutate(start_dt = as.POSIXct(startdate), .row = row_number()) %>%
filter(vpid == 62128, form == "C") %>%
arrange(start_dt, .row) %>%
slice_head(n = 1) %>%
pull(.row)
dat_children_parents <- dat_children_parents %>%
mutate(.row = row_number()) %>%
filter(.row == keep_row_id | !(vpid == 62128 & form == "C")) %>%
select(-.row)
# Project 8
dat_children_parents <- dat_children_parents %>%
mutate(startdate = as.Date(startdate)) %>%
group_by(vpid, form) %>%
filter(!(vpid == 80505 & form == "P" & startdate == max(startdate))) %>%
ungroup()
dat_adults <- dat_adults[!(dat_adults$vpid == 80009 & dat_adults$project == 8), ]
# Project 9
PROJECT = 9;
dat_adults = dat_adults %>%
filter(!(vpid == 90002 & lastpage == 11))
# Auto-remove and check for remaining duplicates
# Adults
res_adults <- resolve_duplicates(dat_adults, vp_col, submit_col,
dataset_name = "adults", data_type = "questionnaire",
project_col, logger = logger)
dat_adults    <- res_adults$cleaned
trash_adults  <- res_adults$trash_bin
# Adolescents
res_adolescents <- resolve_duplicates(dat_adolescents, vp_col, submit_col,
dataset_name = "adolescents", data_type = "questionnaire",
project_col, logger = logger)
dat_adolescents   <- res_adolescents$cleaned
trash_adolescents <- res_adolescents$trash_bin
# Children/Parents
res_children_parents <- resolve_duplicates(dat_children_parents, vp_col, submit_col,
dataset_name = "children_parents", data_type = "questionnaire",
project_col, logger = logger)
dat_children_parents  <- res_children_parents$cleaned
trash_children_parents<- res_children_parents$trash_bin
# Project 6 children parents
vp_col <- "VPCode"
res_children_p6 <- resolve_duplicates(dat_children_p6, vp_col, submit_col,
dataset_name = "children_p6", data_type = "questionnaire",
project_col, lastpage_threshold = 13, logger = logger)
dat_children_p6 <- res_children_p6$cleaned
trash_children_p6 <- res_children_p6$trash_bin
res_parents_p6 <- resolve_duplicates(dat_parents_p6, vp_col, submit_col,
dataset_name = "parents_p6", data_type = "questionnaire",
project_col, lastpage_threshold = 13, logger = logger)
dat_parents_p6 <- res_parents_p6$cleaned
trash_parents_p6 <- res_parents_p6$trash_bin
# Special Case Project 8: Check C, P and A entries -----------------------------
check_vpid_forms(dat_children_parents, logger = logger)
# Save the Trash just to be safe -----------------------------------------------
all_trash_adults      <- rbind(all_empty_ad, trash_adults)
all_trash_children    <- rbind(all_empty_ch, trash_children_parents)
all_trash_adolescents <- rbind(empty_adlsc_7, trash_adolescents)
write_xlsx(all_trash_adults,      file.path(out_path, "discarded", sprintf("deleted-rows_%s_adults.xlsx", today)))
write_xlsx(all_trash_children,    file.path(out_path, "discarded", sprintf("deleted-rows_%s_children.xlsx", today)))
write_xlsx(all_trash_adolescents, file.path(out_path, "discarded", sprintf("deleted-rows_%s_adolescents.xlsx", today)))
# Separate the data by project and store on disk -------------------------------
samples <- list(
adults          = dat_adults,
adolescents     = dat_adolescents,
children_parents= dat_children_parents,
children_p6     = dat_children_p6,
parents_p6      = dat_parents_p6
)
# Questionnaires
lapply(names(samples), function(s) {
prep <- prepare_project_slices(samples[[s]], out_path = out_path, sample = s, data_type = "questionnaires", metadata_info = quest_info)
prep <- analyze_rushing(prep)
write_project_slices(prep)
})
##########################################################################
## Data Cleaning for Cognitive Test Data ---------------------------------
##########################################################################
# Set column name variables ----------------------------------------------------
vp_col     <- "id"
project_col<- "p"
# last_page <- "lastpage"
link_col   <- "comp"
id_col     <- NA    # psytoolkit info sheets: vpid; questionnaires: unique increment counter
submit_col <- "TIME_end"
start_col  <- "TIME_start"
# Fix issues with project assignment ------------------------------------------
psytool_info_adults[[project_col]][which(psytool_info_adults[[vp_col]] == 2048)]  <- 2
psytool_info_adults[[project_col]][which(psytool_info_adults[[vp_col]] == 99017)] <- 9
# Remove empty Rows ------------------------------------------------------------
list_output           <- partition_empty_obs_psytoolkit(psytool_info_adults)
psytool_info_adults   <- list_output$kept
no_id_ad              <- list_output$no_id
empty_rows_ad         <- list_output$empty
# TODO: need to understand how it is possible to generate entries without ID - and possibly reconstruct?
list_output               <- partition_empty_obs_psytoolkit(psytool_info_adolescents)
psytool_info_adolescents  <- list_output$kept
no_id_adlsc               <- list_output$no_id
empty_rows_adlsc          <- list_output$empty
list_output            <- partition_empty_obs_psytoolkit(psytool_info_children)
psytool_info_children  <- list_output$kept
no_id_ch               <- list_output$no_id
empty_rows_ch          <- list_output$empty
# Fix ID naming issues ---------------------------------------------------------
# Project 2
PROJECT <- 2
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 20035)] <- 20036
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 4    & psytool_info_adults[[project_col]] == PROJECT)] <- 20004
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 6    & psytool_info_adults[[project_col]] == PROJECT)] <- 20006
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 15   & psytool_info_adults[[project_col]] == PROJECT)] <- 20015
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2023 & psytool_info_adults[[project_col]] == PROJECT)] <- 20023
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 26   & psytool_info_adults[[project_col]] == PROJECT)] <- 20026
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 35   & psytool_info_adults[[project_col]] == PROJECT)] <- 20035
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2041 & psytool_info_adults[[project_col]] == PROJECT)] <- 20041
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2044 & psytool_info_adults[[project_col]] == PROJECT)] <- 20044
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2046 & psytool_info_adults[[project_col]] == PROJECT)] <- 20046
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2048 & psytool_info_adults[[project_col]] == PROJECT)] <- 20048
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2051 & psytool_info_adults[[project_col]] == PROJECT)] <- 20051
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 2052 & psytool_info_adults[[project_col]] == PROJECT)] <- 20052
# Project 3
PROJECT <- 3
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 1 & psytool_info_adults[[project_col]] == PROJECT)] <- 30001
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 3 & psytool_info_adults[[project_col]] == PROJECT)] <- 30003
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 8 & psytool_info_adults[[project_col]] == PROJECT)] <- 30008
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 9 & psytool_info_adults[[project_col]] == PROJECT)] <- 30009
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 10002 & psytool_info_adults[[project_col]] == PROJECT)] <- 30002
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 10005 & psytool_info_adults[[project_col]] == PROJECT)] <- 30005
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 10006 & psytool_info_adults[[project_col]] == PROJECT)] <- 30006
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 10007 & psytool_info_adults[[project_col]] == PROJECT)] <- 30007
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 40019 & psytool_info_adults[[project_col]] == PROJECT)] <- 30019
# Falsely named datasets -----------------------------
psytool_info_adults$id <- suppressWarnings(as.integer(psytool_info_adults$id))
psytool_info_adults <- psytool_info_adults %>%
group_by(id) %>%
mutate(
id = dplyr::case_when(
id == 30048L & p == 3 & TIME_start == max(TIME_start) ~ 30047L,
id == 30058L & p == 3 & TIME_start == max(TIME_start) ~ 30057L,
TRUE ~ id
)
) %>%
ungroup()
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 219 & psytool_info_adults[[project_col]] == PROJECT)] <- 30002
# Project 4
PROJECT <- 4
# assuming a 0 (or many) 0s are missing
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 4001 & psytool_info_adults[[project_col]] == PROJECT)] <- 40001
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 4002 & psytool_info_adults[[project_col]] == PROJECT)] <- 40002
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 4003 & psytool_info_adults[[project_col]] == PROJECT)] <- 40003
# Project 8
PROJECT <- 8
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 800028 & psytool_info_adults[[project_col]] == PROJECT)] <- 80028
# Project 9
PROJECT <- 9
psytool_info_adults[[vp_col]][which(psytool_info_adults[[vp_col]] == 9901)] <- 99001
# Special Case Project 8: Remap VPIDs so children and adults have unique IDs --
psytool_info_children <- correct_child_vpids(
psytool_info_children, vpid_col = "id", project_col = "p",  startdate_col = "TIME_start",
mapping_file = file.path("information", "2025-08-19_Neuzuordnung_VP-IDs_Kinder-Sample_Projekt_8.xlsx")
)
# Gather Pilot Participant IDs -------------------------------------------------
pilots_ad_auto  <- find_pilot_ids(dat_general, psytool_info_adults,      vpid_col_df2 = vp_col)
pilots_asc_auto <- find_pilot_ids(dat_general, psytool_info_adolescents, vpid_col_df2 = vp_col)
pilots_ch_auto  <- find_pilot_ids(dat_general, psytool_info_children,    vpid_col_df2 = vp_col)
pilot_ad_2  <- c(20004)
pilot_ad_9  <- c()
pilot_ad_8  <- c(80350)
pilot_asc_7 <- c()
pilot_ch_6  <- c(62973, 62980, 62998, 62992, 62987, 62989, 62994, 62970)
pilot_ad_all  <- c(pilot_ad_2, pilot_ad_9, pilot_ad_8, pilots_ad_auto)
pilot_asc_all <- c(pilots_asc_auto)
pilots_ch_all <- c(pilots_ch_auto, pilot_ch_6)
# --- save P9 (and all) pilot rows before extracting them out ------------------
pilot_psytool_adults <- dplyr::filter(psytool_info_adults, .data[[vp_col]] %in% pilot_ad_all)
# Move to separate file and from original dataset -----------------------------
psytool_info_adults <- extract_pilot_by_vpid(
psytool_info_adults, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilot_ad_all, sample = "psytool_adults", vpid_col = vp_col
)
psytool_info_adolescents <- extract_pilot_by_vpid(
psytool_info_adolescents, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilot_asc_all, sample = "psytool_adolescents", vpid_col = vp_col
)
psytool_info_children <- extract_pilot_by_vpid(
psytool_info_children, out_path = file.path(out_path, "pilots"), export_csv = FALSE,
pilot_ids = pilots_ch_all, sample = "psytool_children", vpid_col = vp_col
)
# Handle duplicate IDs ---------------------------------------------------------
# Delete not needed, incomplete or faulty datasets -----------------------------
# Project 3 — Hendrik said they can be deleted
psytool_info_adults <- psytool_info_adults %>%
group_by(.data[[vp_col]]) %>%
filter(!(.data[[vp_col]] == 30009 & .data[[start_col]] != max(.data[[start_col]]))) %>%
ungroup()
psytool_info_adults <- psytool_info_adults[!(psytool_info_adults$id == 80009 & psytool_info_adults$p == 8), ]
# Adults
res_adults <- resolve_duplicates(psytool_info_adults, vp_col, submit_col,
dataset_name = "adults", data_type = "experiment_data",
project_col, logger = logger)
psytool_info_adults <- res_adults$cleaned
trash_adults        <- res_adults$trash_bin
# Adolescents
res_adolescents <- resolve_duplicates(psytool_info_adolescents, vp_col, submit_col,
dataset_name = "adolescents", data_type = "experiment_data",
project_col, logger = logger)
psytool_info_adolescents <- res_adolescents$cleaned
trash_adolescents        <- res_adolescents$trash_bin
# Children
res_children <- resolve_duplicates(psytool_info_children, vp_col, submit_col,
dataset_name = "children", data_type = "experiment_data",
project_col, logger = logger)
psytool_info_children <- res_children$cleaned
trash_children        <- res_children$trash_bin
# Separate the data by project and store on disk -------------------------------
# Cognitive Tests
samples <- list(
adults          = psytool_info_adults,
adolescents     = psytool_info_adolescents,
children_parents= psytool_info_children
)
# Cogtests
variable_output_paths = lapply(names(samples), function(s) {
prep <- prepare_project_slices(samples[[s]], out_path = out_path, sample = s, data_type = "experiment_data", metadata_info = cogtest_info)
write_project_slices(prep)
})
names(variable_output_paths) <- names(samples)
# ================= Pilot exception for Project 9 ==============================
# Save pilot rows that belong to project 9 into '<pid>_backbone/pilot_data/'
# using separate_by_project(..., pilot_mode = TRUE).
write_p9_pilots <- function(df, sample_label, data_type, metadata_info) {
if (is.null(df) || !NROW(df)) return(invisible(NULL))
# Detect the project column robustly
proj_candidates <- c("project", "Projekt...Project", "Projekt.", "Projekt",
"projekt", "p", "proj", "Proj")
lower_names <- tolower(names(df))
hit <- match(tolower(proj_candidates), lower_names)
hit <- hit[!is.na(hit)][1]
if (is.na(hit)) return(invisible(NULL))
proj_col <- names(df)[hit]
sub <- df[trimws(as.character(df[[proj_col]])) %in% c("9","P9","Project 9","9."), , drop = FALSE]
if (!NROW(sub)) return(invisible(NULL))
separate_by_project(
sub,
out_path      = out_path,
sample        = sample_label,
export_csv    = FALSE,
data_type     = data_type,
metadata_info = metadata_info,
pilot_mode    = TRUE,
verbose       = TRUE
)
}
# --- Questionnaires (use quest_info) -----------------------------------------
write_p9_pilots(pilot_quest_adults, "adults", "questionnaires", quest_info)
# --- PsyToolkit (cognitive; use cogtest_info) --------------------------------
write_p9_pilots(pilot_psytool_adults, "adults", "experiment_data", cogtest_info)
# Build logger dest map robustly from the file paths we just wrote
build_dest_dirs <- function(paths_vec) {
# Flatten + drop empties
paths_vec <- as.character(unlist(paths_vec, use.names = FALSE))
paths_vec <- paths_vec[nzchar(paths_vec)]
if (!length(paths_vec)) stop("No output paths to derive per-project destinations from.")
find_backbone_root <- function(p) {
p <- normalizePath(p, winslash = "/", mustWork = FALSE)
if (!nzchar(p)) return(NA_character_)
# if it's a file, start at its directory
cur <- if (file.exists(p) && !dir.exists(p)) dirname(p) else p
# climb until we hit X_backbone
for (i in 1:10) {
base <- basename(cur)
if (grepl("^[0-9]+_backbone$", base)) return(cur)
parent <- dirname(cur)
if (identical(parent, cur)) break
cur <- parent
}
NA_character_
}
roots <- vapply(paths_vec, find_backbone_root, character(1))
roots <- unique(roots[!is.na(roots)])
if (!length(roots)) stop("No per-project folders (<digits>_backbone) found among the given paths.")
proj_keys <- sub("^([0-9]+).*", "\\1", basename(roots))
stats::setNames(roots, proj_keys)
}
# Use adults (any sample works; they all produce the same project set)
dest_dirs <- build_dest_dirs(variable_output_paths$adults)
# (Optional) clear old .log files in those project folders
for (dir in dest_dirs) {
if (dir.exists(dir)) {
log_files <- list.files(dir, pattern = "\\.log$", full.names = TRUE)
if (length(log_files)) {
message("Removing existing log files in: ", dir)
file.remove(log_files)
}
}
}
# Split the main log into the per-project folders
logger$split(dest_dirs)
# --- REPLACE up to here --------------------------------------------------------
# 4️⃣ Close when done
logger$close()
## Get the Experimental Data Sets Associated with the project ------------------
# copy TXT files for all per-project cogtests AND mirror into all_projects_backbone
log_copy <- copy_psytool_files(
env_objects       = ls(pattern = "^data_.*_p_[0-9]+_cogtest$"),
cogtest_out_path  = out_path,          # "01_project_data"
meta_env_name     = "cogtest_info",
test_cols         = NULL,              # let it auto-detect
allowed_projects  = as.character(2:9),
middle_subdir     = NULL,
purge_old_dated   = TRUE,              # delete old *_cogtest_data before copying
write_all_projects= TRUE               # also write ALL_<date>_*_cogtest_data
)
# Expose the P9 adults pilot subset under the name copy_psytool_files() expects
if (exists("pilot_psytool_adults") && NROW(pilot_psytool_adults)) {
data_adults_p_9_cogtest <- pilot_psytool_adults
}
# Copy P9 adults pilot experiment files under 01_project_data/9_backbone/pilot_data/experiment_data/...
copy_psytool_files(
env_objects      = "data_adults_p_9_cogtest",
cogtest_out_path = out_path,
meta_env_name    = "cogtest_info",
allowed_projects = "9",
middle_subdir    = "pilot_data"   # <<< puts results under pilot_data/experiment_data
)
## Print the final list of IDs to Disk -----------------------------------------
collect_ids_to_excel(
meta_data = quest_info,
dat_adults,
dat_adolescents,
dat_children_parents,
dat_children_p6,
dat_parents_p6,
submit_date_col = "startdate",
id_col = "vpid",
project_col = "project",
data_type = "questionnaire"
)
collect_ids_to_excel(
meta_data = quest_info,
dat_children_p6,
dat_parents_p6,
submit_date_col = "startdate",
id_col = "VPCode",
project_col = NULL,
data_type = "questionnaire_p6"
)
collect_ids_to_excel(
meta_data = cogtest_info,
psytool_info_adults,
psytool_info_adolescents,
psytool_info_children,
submit_date_col = "TIME_start",
id_col = "id",
project_col = "p",
data_type = "cogtest"
)
## Data Sanity Check -----------------------------------------
## ------------- helpers -------------
# Canonical key: lowercase + remove all non-alphanumerics
.canon_key <- function(x) {
x <- tolower(x)
gsub("[^a-z0-9]", "", x, perl = TRUE)
}
# Normalize item/scale mapping to columns: item, scale, item_key
.normalize_item_info <- function(item_info_adults) {
ii <- item_info_adults %>%
rename_with(~ "item",  dplyr::matches("(?i)^item$")) %>%
rename_with(~ "scale", dplyr::matches("(?i)^scale$")) %>%
mutate(
item     = as.character(item),
scale    = as.character(scale),
item_key = .canon_key(item)
) %>%
distinct(item, scale, item_key)
# warn if different item names collapse to same key
dup_keys <- ii %>% count(item_key) %>% filter(n > 1)
if (nrow(dup_keys) > 0) {
warning("Multiple Item names collapse to the same canonical key: ",
paste0(dup_keys$item_key, collapse = ", "),
". Disambiguate Item names if this is unintended.")
}
ii
}
# Normalize scoring to columns: scale, min, max
.normalize_scoring_info <- function(scoring_info) {
scoring_info %>%
rename_with(~ "scale", dplyr::matches("(?i)^scale$")) %>%
rename_with(~ "min",   dplyr::matches("(?i)^min$")) %>%
rename_with(~ "max",   dplyr::matches("(?i)^max$")) %>%
mutate(scale = as.character(scale)) %>%
select(scale, min, max)
}
# Link mapping items to actual data columns (handles brackets/dots via canonical keys)
# Returns: list(link, present, missing)
.build_item_link <- function(dat, item_info_adults) {
ii <- .normalize_item_info(item_info_adults) %>%
mutate(item_key = .canon_key(item))
dat_cols <- tibble(
data_col = names(dat),
data_key = .canon_key(names(dat))
)
# join item_key (mapping) -> data_key (actual columns)
link <- ii %>%
left_join(dat_cols, by = c("item_key" = "data_key")) %>%
select(item, scale, item_key, data_col)
# for QC we only care about true scales, not admin fields
present <- link %>% filter(!is.na(data_col), !is.na(scale))
missing <- link %>% filter(is.na(data_col), !is.na(scale))
# warn if data columns canonicalize to the same key (rare)
dup_dat_keys <- dat_cols %>% count(data_key) %>% filter(n > 1)
if (nrow(dup_dat_keys) > 0) {
warning("Multiple data columns collapse to the same canonical key: ",
paste0(dup_dat_keys$data_key, collapse = ", "),
". Consider cleaning column names to avoid ambiguity.")
}
list(link = link, present = present, missing = missing)
}
# expect objects named data_adults_p_1_questionnaire ... _p_9_questionnaire
dataset_names <- sprintf("data_adults_p_%d_questionnaire", 1:9)
dataset_names <- dataset_names[dataset_names %in% ls(envir = .GlobalEnv)]
datasets <- mget(dataset_names, envir = .GlobalEnv)
# run QC on each dataset
qc_results <- imap(datasets, function(dat, nm) {
message("\n--- QC for ", nm, " ---")
# quick mapping counts (optional; useful for sanity)
lp <- .build_item_link(dat, item_info_adults)
message("Mapped items: ", nrow(lp$present), "  |  Unmapped (in mapping but not in data): ", nrow(lp$missing))
res <- qc_ranges_and_missing(
dat                  = dat,
item_info_adults     = item_info_adults,
scoring_info         = scoring_info,
id_col               = "vpid",                 # this attaches vpids to outputs
all_or_nothing_scales= c("FHSfamilytree", "CAPE", "SUQ", "health", "demographics", "times"),
exclude_scales_from_qc = c("id")               # <-- ignore the ID scale in QC
)
# concise console output
message("Range violations: ", nrow(res$violations))
if (nrow(res$per_scale_summary) > 0) {
message("Scales with any FULL missing participants:")
print(res$per_scale_summary %>% filter(n_full_missing > 0) %>% arrange(desc(n_full_missing)))
message("Scales with any PARTIAL missing participants (excl. all-or-nothing):")
print(res$per_scale_summary %>% filter(n_partial_missing > 0) %>% arrange(desc(n_partial_missing)))
} else {
message("No mapped scales found (skipped).")
}
invisible(res)
})
