dat_adults <- dat_adults %>%
dplyr::filter(!id %in% del_id_ad)
# --- Example usage with your three datasets ---
# Assume vp_col is a string like "vp_id"
# Adults
res_adults <- resolve_duplicates(dat_adults, vp_col, dataset_name = "adults")
dat_adults <- res_adults$cleaned
trash_adults <- res_adults$trash_bin
# [adults] Multiple complete datasets for vpid=80009 — please resolve manually.
# [adults] Multiple complete datasets for vpid=80011 — please resolve manually.
# [adults] Multiple complete datasets for vpid=99001 — please resolve manually.
# Adolescents
res_adolescents <- resolve_duplicates(dat_adolescents, vp_col, dataset_name = "adolescents")
dat_adolescents <- res_adolescents$cleaned
trash_adolescents <- res_adolescents$trash_bin
# [adolescents] Multiple complete datasets for vpid=70076 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70072 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70084 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70062 — please resolve manually.
# Children/Parents
res_children_parents <- resolve_duplicates(dat_children_parents, vp_col, dataset_name = "children_parents")
dat_children_parents <- res_children_parents$cleaned
trash_children_parents <- res_children_parents$trash_bin
# [children_parents] Multiple incomplete datasets for vpid=62128, form=C — please resolve manually.
# [children_parents] Multiple complete datasets for vpid=80005, form=P — please resolve manually.
#  One combined trash bin for easy cross-checking:
# TODO: save as extra variable (like pilots) and also include empty rows
# Gather Pilot Participant IDs WIP -------------------------------------------------
pilot_ad_2 = c(20002, 20001, 20003, 20004);
pilot_ad_9 = c();
pilot_ad_7 = c(79001, 79002, 79003, 79004, 79005, 79006, 79007, 79008, 79009, 79010, 79011, 79012, 79013, 79014, 79015);
pilot_asc_7 = c(79019, 77001);
pilot_ad_all = c(pilot_ad_2, pilot_ad_7, pilot_ad_9);
pilot_asc_all = c(pilot_asc_7);
# Move to separate file and from original dataset
dat_adults <- extract_pilot_by_vpid(
dat_adults,
out_path = out_path,
export_csv = FALSE,
pilot_ids = pilot_ad_all,
sample = "adults",
vpid_col = "vpid"
);
psytool_info_adults <- extract_pilot_by_vpid(
psytool_info_adults,
out_path = cogtest_out_path,
export_csv = FALSE,
pilot_ids = pilot_ad_all,
sample = "adults",
vpid_col = "id"
);
dat_adolescents <- extract_pilot_by_vpid(
dat_adolescents,
out_path = out_path,
export_csv = FALSE,
pilot_ids = pilot_asc_all,
sample = "adolescents",
vpid_col = "vpid"
);
# Separate the data by project and store on disk ------------------------------
# Questionnaires
separate_by_project(dat_adults, out_path, "adults")
separate_by_project(dat_adolescents, out_path, "adolescents")
separate_by_project(dat_children_parents, out_path, "children")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# FOR: translate remids
# Author: Saskia Wilken (saskia.wilken@uni-hamburg.de)
# 2025-08-26
#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This script
# - reads the "children/parents" and "adults" questionnaire data
# - loads Remote ↔ Participant ID mappings from the Excel sheet "Combined"
# - fixes known data-entry issues before any checks
# - requires remid == remidcheck (except when remid == "XXXXX")
# - if remid == "XXXXX", uses remidcheck as the final vpid (and logs these rows)
# - for valid rows, maps Remote_ID → Participant_ID, writes to vpid, and clears remid/remidcheck
# - saves the updated data as "..._remids_translated.csv"
# clean up R environment
rm(list = ls())
cat("\014")
# install & load required packages --------------------------------------------
pkg <- c("dplyr", "readxl", "rstudioapi")
to_install <- pkg[!sapply(pkg, require, character.only = TRUE)]
if (length(to_install)) install.packages(to_install, dependencies = TRUE)
invisible(lapply(pkg, library, character.only = TRUE))
# number display ---------------------------------------------------------------
options(scipen = 999)
# paths ------------------------------------------------------------------------
# Script directory (works in RStudio; falls back to current working directory)
script_dir <- tryCatch(dirname(rstudioapi::getSourceEditorContext()$path),
error = function(e) getwd())
in_path      <- file.path(script_dir, "raw_data")
info_path    <- file.path(script_dir, "information")
# optional log dir for Project 8 special-case notes
log_dir <- file.path(script_dir, "01_project_data", "logs")
if (!dir.exists(log_dir)) dir.create(log_dir, recursive = TRUE, showWarnings = FALSE)
file_children_parents <- "results-survey798916.csv"
file_adults           <- "results-survey564757.csv"
out_children_parents  <- "results-survey798916_remids_translated.csv"
out_adults            <- "results-survey564757_remids_translated.csv"
xlsx_file   <- "2025-08-20_Remote-IDs_Projekt_8_Extended_SW.xlsx"
xlsx_sheet  <- "Combined"
# load data --------------------------------------------------------------------
dat_children_parents <- read.csv(file.path(in_path, file_children_parents),
sep = ";", stringsAsFactors = FALSE, check.names = FALSE)
dat_adults <- read.csv(file.path(in_path, file_adults),
sep = ";", stringsAsFactors = FALSE, check.names = FALSE)
# load mapping (Participant_ID, Remote_ID) from Excel --------------------------
map_ids <- readxl::read_excel(file.path(info_path, xlsx_file), sheet = xlsx_sheet) |>
dplyr::select(Participant_ID, Remote_ID) |>
dplyr::mutate(
Participant_ID = as.character(Participant_ID),
Remote_ID      = as.character(Remote_ID)
)
# fix known data-entry errors --------------------------------------------------
# 1) Extend mapping with special cases (all map to vpid 99999)
special_map <- data.frame(
Participant_ID = rep("99999", 8),
Remote_ID      = c("99", "999", "9999", "99999", "999999", "9999999", "R70999", "10"),
stringsAsFactors = FALSE
)
map_ids <- dplyr::bind_rows(map_ids, special_map) |>
dplyr::distinct(Remote_ID, .keep_all = TRUE)
# 2) Correct mis-typed remid in raw survey data (805199 → 80519) in-memory only
fix_mistyped_remid <- function(df) {
if (is.numeric(df$remid)) {
df$remid[df$remid == 805199] <- 80519
} else {
df$remid[df$remid == "805199"] <- "80519"
}
df
}
dat_children_parents <- fix_mistyped_remid(dat_children_parents)
dat_adults           <- fix_mistyped_remid(dat_adults)
# utilities --------------------------------------------------------------------
is_blank <- function(x) is.na(x) | x == ""
# Handle special "XXXXX" case: set vpid from remidcheck and log ----------------
handle_xxxxx <- function(df, dataset_name) {
remid_chr  <- as.character(df$remid)
check_chr  <- as.character(df$remidcheck)
xmask <- !is.na(remid_chr) & toupper(remid_chr) == "XXXXX" & !is_blank(check_chr)
log_df <- NULL
if (any(xmask)) {
# Assign vpid from remidcheck for these rows
df$vpid[xmask]        <- check_chr[xmask]
# Clear remid & remidcheck afterwards
df$remid[xmask]       <- NA
df$remidcheck[xmask]  <- NA
# Prepare a log for Project 8
log_df <- data.frame(
dataset      = dataset_name,
row_index    = which(xmask),
remid_used   = "XXXXX",
vpid_from_remidcheck = check_chr[xmask],
stringsAsFactors = FALSE
)
}
list(df = df, log = log_df)
}
# Identity check before any mapping (except for the "XXXXX" rows) --------------
#  - if remid & remidcheck are BOTH non-blank and NOT identical -> print and skip mapping
#  - if one or both are blank -> proceed (that's typical)
#  - "XXXXX" rows are handled above and excluded from mismatch warnings
flag_and_report_mismatches <- function(df, dataset_name) {
remid_chr  <- as.character(df$remid)
check_chr  <- as.character(df$remidcheck)
xmask <- !is.na(remid_chr) & toupper(remid_chr) == "XXXXX"
both_present <- !is_blank(remid_chr) & !is_blank(check_chr)
mismatch <- both_present & (remid_chr != check_chr) & !xmask
if (any(mismatch)) {
idx <- which(mismatch)
cat("\n[", dataset_name, "] remid vs remidcheck mismatch rows (", length(idx), "):\n", sep = "")
for (i in idx) {
cat("  row ", i, ": remid='", remid_chr[i], "', remidcheck='", check_chr[i], "' -> MANUAL CHECK NEEDED (skipped)\n", sep = "")
}
}
# Return a logical vector of rows eligible for mapping (exclude mismatches)
eligible <- !mismatch
eligible
}
# Unmapped check (ignores letter-only, ignores 'XXXXX', ignores mismatches) ----
find_unmapped <- function(df, remote_ids, eligible_rows) {
remid_chr  <- as.character(df$remid)
check_chr  <- as.character(df$remidcheck)
xmask      <- !is.na(remid_chr) & toupper(remid_chr) == "XXXXX"
use_mask   <- eligible_rows & !xmask & !is_blank(remid_chr)
candidates <- remid_chr[use_mask]
# Keep only numeric or whitelisted "R70999"
is_numeric <- grepl("^[0-9]+$", candidates)
whitelist  <- candidates %in% c("R70999")
candidates <- candidates[is_numeric | whitelist]
setdiff(candidates, as.character(remote_ids))
}
# translate function (applies only to eligible rows) ---------------------------
translate_remids <- function(df, map_tbl, eligible_rows) {
# Join key
df$remid_chr <- as.character(df$remid)
# Do the join
df <- df |>
dplyr::left_join(map_tbl, by = c("remid_chr" = "Remote_ID"))
# Apply translation only on eligible rows where mapping exists
can_translate <- eligible_rows & !is_blank(df$remid_chr) & !is.na(df$Participant_ID)
df$vpid[can_translate] <- df$Participant_ID[can_translate]
# Clear remid & remidcheck after successful translation
df$remid[can_translate]      <- NA
df$remidcheck[can_translate] <- NA
# Cleanup
df <- dplyr::select(df, -remid_chr, -Participant_ID)
df
}
# PROCESS: children/parents ----------------------------------------------------
res_cp <- handle_xxxxx(dat_children_parents, "children_parents")
dat_children_parents <- res_cp$df
log_cp <- res_cp$log
eligible_cp <- flag_and_report_mismatches(dat_children_parents, "children/parents")
unmapped_children <- find_unmapped(dat_children_parents, map_ids$Remote_ID, eligible_cp)
if (length(unmapped_children) > 0) {
cat("\n[children/parents] remids without mapping (n=", length(unmapped_children), "):\n", sep = "")
print(unmapped_children)
stop("\nUnmapped remids detected (ignoring letter-only and 'XXXXX', and skipping mismatches). Please update the Excel mapping and re-run.")
}
dat_children_parents_out <- translate_remids(dat_children_parents, map_ids, eligible_cp)
# PROCESS: adults --------------------------------------------------------------
res_ad <- handle_xxxxx(dat_adults, "adults")
dat_adults <- res_ad$df
log_ad <- res_ad$log
eligible_ad <- flag_and_report_mismatches(dat_adults, "adults")
unmapped_adults <- find_unmapped(dat_adults, map_ids$Remote_ID, eligible_ad)
if (length(unmapped_adults) > 0) {
cat("\n[adults] remids without mapping (n=", length(unmapped_adults), "):\n", sep = "")
print(unmapped_adults)
stop("\nUnmapped remids detected (ignoring letter-only and 'XXXXX', and skipping mismatches). Please update the Excel mapping and re-run.")
}
dat_adults_out <- translate_remids(dat_adults, map_ids, eligible_ad)
# Write Project 8 log for 'XXXXX' fallbacks ------------------------------------
log_all <- dplyr::bind_rows(log_cp, log_ad)
if (!is.null(log_all) && nrow(log_all) > 0) {
ts <- format(Sys.time(), "%Y%m%d_%H%M%S")
log_file <- file.path(log_dir, paste0("project8_xxxxx_fallback_log_", ts, ".csv"))
write.table(log_all, file = log_file, sep = ";", dec = ".", row.names = FALSE, qmethod = "double")
cat("\nProject 8 'XXXXX' fallback log written to:\n", log_file, "\n")
}
# save results -----------------------------------------------------------------
write.table(dat_children_parents_out,
file = file.path(in_path, out_children_parents),
sep = ";", dec = ".", row.names = FALSE, qmethod = "double")
write.table(dat_adults_out,
file = file.path(in_path, out_adults),
sep = ";", dec = ".", row.names = FALSE, qmethod = "double")
cat("\nSaved translated data to:\n",
file.path(in_path, out_children_parents), "\n",
file.path(in_path, out_adults), "\n", sep = "")
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#
# FOR: Backbone Separate Data by Project
# Author: Saskia Wilken (saskia.wilken@uni-hamburg.de) & Antonia Bott (antonia.bott@uni-hamburg.de)
# 2025-08-08 (Date initially edited by SW)
#
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# This script
# (1) reads questionnaire data exported from LimeSurvey and PsyToolkit
# (2) Fixes Issues with VP ID assignment
# (3) Creates project-specific data files in the environment as well as on disk
# clean up R environment
rm(list=ls())
cat("\014")
# install packages
if(!require("dplyr")){install.packages("dplyr")};library(dplyr)
if(!require("tidyr")){install.packages("tidyr")};library(tidyr)
if(!require("writexl")){install.packages("writexl")};library(tidyr)
# Esure proper number display -------------------------------------------------
options(scipen = 999)  # disable scientific notation globally
## Set working directory -------------------------------------------------------
whoami<- Sys.info()[[4]]; print(whoami)
# if you are not in this list add your computer here
switch(whoami,
"KOPSY-D-033080" = {name <- "K:/vol2011/bba3488/";
path <- "FOR/"},
"UN-LAP-015977" = {name <- dirname(rstudioapi::getSourceEditorContext()$path);
}
)
setwd(name);
in_path = file.path("raw_data");
out_path = file.path("01_project_data");
survey_out_path = file.path(out_path, "survey_data");
function_path = file.path("functions");
psytool_path = file.path("raw_data", "psytoolkit");
cogtest_out_path = file.path(out_path, "experiment_data");
## Source required functions --------------------
source(file.path(function_path, "separate_by_project.R"))
# source(file.path(function_path, "separate_by_project_cog.R"))
source(file.path(function_path, "remove_test_rows.R"))
source(file.path(function_path, "copy_psytool_files.R"))
source(file.path(function_path, "extract_pilot_by_vpid.R"))
source(file.path(function_path, "resolve_duplicates.R"))
## Backbone surveys ------------------------------------------------------------
#file_adults <-"results_adults_07042025.csv" # SW: not sure why this ID, the survey has a different ID
file_adults <- "results-survey564757_remids_translated.csv"
file_adolescents <- "results-survey585676.csv"
file_children_parents <- "results-survey798916_remids_translated.csv"
## Load data -------------------------------------------------------------------
# Questionnaires
dat_adults <- read.csv(file.path(name,in_path, file_adults), sep = ";")
dat_adolescents <- read.csv(file.path(name,in_path, file_adolescents), sep = ";")
dat_children_parents <- read.csv(file.path(name,in_path, file_children_parents), sep = ";")
names(dat_adults)[1:15]
# Data Overview
file_general <- "results-survey415148.csv"
dat_general <- read.csv(file.path(name,in_path, file_general), sep = ";")
names(dat_general)[1:15]
# Psytoolkit Tests
file_psytool_info = "data.csv";
psytool_info_adults <- read.csv(file.path(name, psytool_path, "adults", file_psytool_info))
psytool_info_children <- read.csv(file.path(name, psytool_path, "children", file_psytool_info))
psytool_info_adults_remote <- read.csv(file.path(name, psytool_path, "adults_remote", file_psytool_info))
# seems unimportant, only test data.
psytool_info_adolescents <- read.csv(file.path(name, psytool_path, "adolescents", file_psytool_info))
# remove Test Datasets from all Project data -----------------------------------
dat_adults <- remove_test_rows(dat_adults, "Adults")
dat_adolescents <- remove_test_rows(dat_adolescents, "Adolescents")
dat_children_parents <- remove_test_rows(dat_children_parents, "Children")
psytool_info_adults <- remove_test_rows(psytool_info_adults, "Adults")
psytool_info_adolescents <- remove_test_rows(psytool_info_adolescents, "Adolescents")
psytool_info_children <- remove_test_rows(psytool_info_children, "Children")
##########################################################################
## Data Cleaning for Questionnaire Data ----------------------------------
##########################################################################
# Set column name variables ----------------------------------------------------
vp_col <- "vpid"
project_col <- "project"
last_page <- "lastpage"
link_col <- "comp"
id_col = "id" # careful - in psytoolkit information sheets, this is the vpid, in the
# questionnaire data this is an unqiue incrementing numbercoutning the datasets
# Fix issues with project assignment -------------------------------------------
dat_adults[[project_col]][which(dat_adults[[vp_col]] == 2048)]
# assuming this is project 2 since project 1 does not collect data and the id starts with a 2
dat_adults[[project_col]][which(dat_adults[[vp_col]] == 2048)] = 2;
dat_adults[[project_col]][which(dat_adults[[vp_col]] == 99017)]
# assuming this is project 9 since project 1 does not collect data and the id
# starts with a 9. also project 9 IDs are actually consecutive and 17 is missing.
dat_adults[[project_col]][which(dat_adults[[vp_col]] == 99017)] = 9;
# Remove empty Rows --------------------------------------------------------
LAST_P_EMPTY = 6;
# empty entries did not get pat page LAST_P_EMPTY. I assume this is a technical issue usually
# and I remove it. I also remove when only cognitive tests were performed sicne thre is no quest data.
# I do not remove incomplete entries in this step
# Project 3
PROJECT = 3;
# adult
sum((dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY)
& dat_children_parents[[project_col]] == PROJECT, na.rm = TRUE)
empty_ch_3 = dat_children_parents[which(
(dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY)
& dat_children_parents[[project_col]] == PROJECT), vp_col]
# 30017
dat_children_parents <- dat_children_parents[!(dat_children_parents[[project_col]] == PROJECT &
(dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY)), ];
# child
sum(dat_adults$last_page < LAST_P_EMPTY & dat_adults[[project_col]] == PROJECT, na.rm = TRUE)
empty_ad_3 = dat_adults[which(dat_adults[[last_page]] < LAST_P_EMPTY & dat_adults[[project_col]] == PROJECT), vp_col]
dat_adults <- dat_adults[!(dat_adults[[project_col]] == PROJECT & dat_adults[[last_page]] < LAST_P_EMPTY), ];
# Project 7
PROJECT = 7;
# adult
sum((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT, na.rm = TRUE)
empty_ad_7 = dat_adults[which((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT), vp_col]
#  79016 70003 70005 70010 keine VP Nummer 70023 70029 70025 70013 70040 70044 70049 70054 70060 70067 70059 70096 70097
dat_adults <- dat_adults[!(dat_adults[[project_col]] == PROJECT &
(dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY)), ];
# adolescent
sum((dat_adolescents[[link_col]] == "cogn" | dat_adolescents[[last_page]] < LAST_P_EMPTY) & dat_adolescents[[project_col]] == PROJECT, na.rm = TRUE)
empty_adlsc_7 = dat_adolescents[which((dat_adolescents[[link_col]] == "cogn" | dat_adolescents[[last_page]] < LAST_P_EMPTY) & dat_adolescents[[project_col]] == PROJECT), vp_col]
#  79019  77001  77001  77001  78050  70002  70008  70002  70016  70015  70017  70023  70027  70026  70034  70039  70038  70033
#  70031  70042  70044  70045  70037  70032  70036  70047  70046  70048  70043  70050  70051  70052  70050  70063  70053  70068
#  70066  70057  70069  70075  70064  70065  70022  70077  70076  70058  70073  70078  70070  70056  70074  70072  70071  70084
#  70062  70088  70085  70090  70086  70089  70093  70092  70100  70098  70099
dat_adolescents <- dat_adolescents[!(dat_adolescents[[project_col]] == PROJECT &
(dat_adolescents[[link_col]] == "cogn" | dat_adolescents[[last_page]] < LAST_P_EMPTY)), ];
# Project 8
PROJECT = 8;
# adult
sum((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT, na.rm = TRUE)
empty_ad_8 = dat_adults[which((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT), vp_col]
# 79016 70003 70005 70010 keine VP Nummer 70023 70029 70025 70013 70040 70044 70049 70054 70060 70067 70059 70096 70097
dat_adults <- dat_adults[!(dat_adults[[project_col]] == PROJECT &
(dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY)), ];
# children
sum((dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY) & dat_children_parents[[project_col]] == PROJECT, na.rm = TRUE)
empty_ch_8 = dat_children_parents[which((dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY) & dat_children_parents[[project_col]] == PROJECT), vp_col]
# 79016 70003 70005 70010 keine VP Nummer 70023 70029 70025 70013 70040 70044 70049 70054 70060 70067 70059 70096 70097
dat_children_parents <- dat_children_parents[!(dat_children_parents[[project_col]] == PROJECT &
(dat_children_parents[[link_col]] == "cogn" | dat_children_parents[[last_page]] < LAST_P_EMPTY)), ];
# Project 9
PROJECT = 9;
sum((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT, na.rm = TRUE)
empty_ad_9 = dat_adults[which((dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY) & dat_adults[[project_col]] == PROJECT), vp_col]
#  99003 99020 99009 99021 99027 99023 99006 99010 99025 99025 99007 99024 99018 99012 99037 99034 99036
dat_adults <- dat_adults[!(dat_adults[[project_col]] == PROJECT & (dat_adults[[link_col]] == "cogn" | dat_adults[[last_page]] < LAST_P_EMPTY)), ];
# Fix ID naming issues --------------------------------------------------------
# Project 2
PROJECT = 2;
# wrong entry
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 20035)] = 20036;
# assuming a 0 (or many) 0s are missing
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 4 & dat_adults[[project_col]] == PROJECT)] = 20004;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 6 & dat_adults[[project_col]] == PROJECT)] = 20006;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 15 & dat_adults[[project_col]] == PROJECT)] = 20015;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2023 & dat_adults[[project_col]] == PROJECT)] = 20023;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 26 & dat_adults[[project_col]] == PROJECT)] = 20026;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 35 & dat_adults[[project_col]] == PROJECT)] = 20035;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2041 & dat_adults[[project_col]] == PROJECT)] = 20041;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2044 & dat_adults[[project_col]] == PROJECT)] = 20044;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2046 & dat_adults[[project_col]] == PROJECT)] = 20046;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2048 & dat_adults[[project_col]] == PROJECT)] = 20048;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2051 & dat_adults[[project_col]] == PROJECT)] = 20051;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 2052 & dat_adults[[project_col]] == PROJECT)] = 20052;
# Project 3
PROJECT = 3;
# assuming a 0 (or many) 0s are missing
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 1 & dat_adults[[project_col]] == PROJECT)] = 30001;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 3 & dat_adults[[project_col]] == PROJECT)] = 30003;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 8 & dat_adults[[project_col]] == PROJECT)] = 30008;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 9 & dat_adults[[project_col]] == PROJECT)] = 30009;
# assuming the wrong initial number was given since the projects in question do not collect data (yet)
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10002 & dat_adults[[project_col]] == PROJECT)] = 30002;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10005 & dat_adults[[project_col]] == PROJECT)] = 30005;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10006 & dat_adults[[project_col]] == PROJECT)] = 30006;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 10007 & dat_adults[[project_col]] == PROJECT)] = 30007;
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 40019 & dat_adults[[project_col]] == PROJECT)] = 30019;
# falsely named datasets
dat_adults[[vp_col]][which(dat_adults[[id_col]] == 227 & dat_adults[[project_col]] == PROJECT)] = 30047;
dat_adults[[vp_col]][which(dat_adults[[id_col]] == 316 & dat_adults[[project_col]] == PROJECT)] = 30057;
# Project 9
# assuming a 0 (or many) 0s are missing
dat_adults[[vp_col]][which(dat_adults[[vp_col]] == 9901)] = 99001
# Special Case Project 8: Remap VPIDs so children and adults have unqiue IDs -------------
# TODO: do it.
# Special Case Project 8: Check if all children_parents questionnaire sets have C, P and A entries ----
# TODO: do it
# Handle duplicate IDs ---------------------------------------------------------
# list of duplicates
# sort(unique(dat_adults[[vp_col]][duplicated(dat_adults[[vp_col]])]))
# sort(unique(dat_adolescents[[vp_col]][duplicated(dat_adolescents[[vp_col]])]))
# sort(unique(dat_children_parents[[vp_col]][duplicated(dat_children_parents[[vp_col]])]))
# Delete not needed, incomplete or faulty datasets
# using list of "ids" that can be deleted
# these are the entries in the output file, not the vp identifiers.
del_id_ad = c(59, 80) # Hendrik Heinbockel said they can be deleted as they are incomplete
dat_adults <- dat_adults %>%
dplyr::filter(!id %in% del_id_ad)
# --- Example usage with your three datasets ---
# Assume vp_col is a string like "vp_id"
# Adults
res_adults <- resolve_duplicates(dat_adults, vp_col, dataset_name = "adults")
dat_adults <- res_adults$cleaned
trash_adults <- res_adults$trash_bin
# [adults] Multiple complete datasets for vpid=80009 — please resolve manually.
# [adults] Multiple complete datasets for vpid=80011 — please resolve manually.
# [adults] Multiple complete datasets for vpid=99001 — please resolve manually.
# Adolescents
res_adolescents <- resolve_duplicates(dat_adolescents, vp_col, dataset_name = "adolescents")
dat_adolescents <- res_adolescents$cleaned
trash_adolescents <- res_adolescents$trash_bin
# [adolescents] Multiple complete datasets for vpid=70076 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70072 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70084 — please resolve manually.
# [adolescents] Multiple complete datasets for vpid=70062 — please resolve manually.
# Waiting for resonse from Ibrahim....
# Children/Parents
res_children_parents <- resolve_duplicates(dat_children_parents, vp_col, dataset_name = "children_parents")
dat_children_parents <- res_children_parents$cleaned
trash_children_parents <- res_children_parents$trash_bin
# [children_parents] Multiple incomplete datasets for vpid=62128, form=C — please resolve manually.
# [children_parents] Multiple complete datasets for vpid=80005, form=P — please resolve manually.
#  One combined trash bin for easy cross-checking:
# TODO: save as extra variable (like pilots) and also include empty rows
# Gather Pilot Participant IDs WIP -------------------------------------------------
# TODO: use the general_info to obtain the info which type of data collection was performed.
pilot_ad_2 = c(20002, 20001, 20003, 20004);
pilot_ad_9 = c();
pilot_ad_7 = c(79001, 79002, 79003, 79004, 79005, 79006, 79007, 79008, 79009, 79010, 79011, 79012, 79013, 79014, 79015, 79016);
pilot_asc_7 = c(79019, 77001);
pilot_ad_all = c(pilot_ad_2, pilot_ad_7, pilot_ad_9);
pilot_asc_all = c(pilot_asc_7);
# Move to separate file and from original dataset
dat_adults <- extract_pilot_by_vpid(
dat_adults,
out_path = out_path,
export_csv = FALSE,
pilot_ids = pilot_ad_all,
sample = "adults",
vpid_col = "vpid"
);
psytool_info_adults <- extract_pilot_by_vpid(
psytool_info_adults,
out_path = cogtest_out_path,
export_csv = FALSE,
pilot_ids = pilot_ad_all,
sample = "adults",
vpid_col = "id"
);
dat_adolescents <- extract_pilot_by_vpid(
dat_adolescents,
out_path = out_path,
export_csv = FALSE,
pilot_ids = pilot_asc_all,
sample = "adolescents",
vpid_col = "vpid"
);
