#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# FOR: Separate Backbone Data by Project  â€” Cleaning & Export Pipeline
# Authors: Saskia Wilken (saskia.wilken@uni-hamburg.de, saskia.a.wilken@gmail.com) &
#          Antonia Bott (antonia.bott@uni-hamburg.de)
# First edited: 2025-08-08 (SW)
#
# Description:
# This script reads questionnaire data (LimeSurvey, PsyToolkit), fixes known
# VP-ID issues, removes test/empty entries, separates data per project, exports
# cleaned datasets (and discarded rows) to disk, and manages logging.
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# Clean up R environment -------------------------------------------------------
rm(list = ls())
cat("\014")

# Install/load packages --------------------------------------------------------
if (!require("dplyr"))     { install.packages("dplyr")     }; library(dplyr)
if (!require("tidyr"))     { install.packages("tidyr")     }; library(tidyr)
if (!require("writexl"))   { install.packages("writexl")   }; library(writexl)
if (!require("rstudioapi")){ install.packages("rstudioapi")}; library(rstudioapi)
if (!require("readxl"))    { install.packages("readxl")}; library(readxl)
if (!require("purrr")){ install.packages("purrr")}; library(purrr)
if (!require("stringr")){ install.packages("stringr")}; library(stringr)
if (!require("rlang")){ install.packages("rlang")}; library(rlang)


# Ensure proper number display -------------------------------------------------
options(scipen = 999)  # disable scientific notation globally

# Get Today -------------------------------------------------------------------
today <- format(Sys.Date(), "%Y-%m-%d")

# Set working directory -----------------------------------------------
whoami <- Sys.info()[["nodename"]]
if (is.null(whoami) || is.na(whoami)) whoami <- Sys.info()[[4]]
print(whoami)

# If you are not in this list, a sensible default is used
name <- switch(
  whoami,
  "KOPSY-D-033080" = "K:/vol2011/bba3488/",
  "UN-LAP-015977"  = {
    if (rstudioapi::isAvailable()) {
      dirname(rstudioapi::getSourceEditorContext()$path)
    } else {
      getwd()
    }
  },
  # default fallback
  getwd()
)

setwd(name)

in_path          <- file.path("raw_data")
out_path         <- file.path("01_project_data")
function_path    <- file.path("functions")
psytool_path     <- file.path("raw_data", "psytoolkit")
cogtest_out_path <- file.path(out_path, "experiment_data")

# Specify the folder path
discarded_path <- file.path(out_path, "discarded")

# Check if the folder exists
if (!dir.exists(discarded_path)) {
  dir.create(discarded_path, recursive = TRUE)
}

# ---------- shared helpers ----------
safe_read_csv <- function(path, sep = NULL) {
  if (!file.exists(path)) stop("Missing file: ", path)
  if (is.null(sep)) {
    read.csv(path)
  } else {
    read.csv(path, sep = sep)
  }
}

.detect_script_dir <- function() {
  args <- commandArgs(trailingOnly = FALSE)
  idx <- grep("^--file=", args)
  if (length(idx)) {
    p <- sub("^--file=", "", args[idx[length(idx)]])
    if (nzchar(p)) return(dirname(normalizePath(p, mustWork = FALSE)))
  }
  if (requireNamespace("rstudioapi", quietly = TRUE)) {
    p <- tryCatch(rstudioapi::getActiveDocumentContext()$path, error = function(e) "")
    if (nzchar(p)) return(dirname(normalizePath(p, mustWork = FALSE)))
  }
  if (requireNamespace("knitr", quietly = TRUE)) {
    p <- tryCatch(knitr::current_input(dir = TRUE), error = function(e) "")
    if (nzchar(p)) return(dirname(normalizePath(p, mustWork = FALSE)))
  }
  ""
}
.sanitize_base <- function(p) {
  if (is.null(p)) return(NULL)
  p2 <- normalizePath(p, winslash = "/", mustWork = FALSE)
  tail <- tolower(basename(p2))
  if (tail %in% c("experiment_data", "questionnaires")) dirname(p2) else p2
}
.normalize_sample <- function(x) {
  x <- tolower(x)
  if (grepl("parents_p6", x)) return("parents_p6")
  if (grepl("children_p6", x)) return("children_p6")
  if (grepl("children_parents", x)) return("children_parents")
  if (grepl("(?:^|[_\\.-])(children)(?:$|[_\\.-])", x)) return("children_parents")
  if (grepl("(?:^|[_\\.-])(adolescents)(?:$|[_\\.-])", x)) return("adolescents")
  if (grepl("(?:^|[_\\.-])(adults)(?:$|[_\\.-])", x)) return("adults")
  "unknown"
}
.infer_sample_from_call <- function(df) {
  txt1 <- tryCatch(paste(deparse(substitute(df)), collapse = ""), error = function(e) "")
  s1 <- .normalize_sample(txt1); if (s1 != "unknown") return(s1)
  mc <- tryCatch(match.call(expand.dots = FALSE)$df, error = function(e) NULL)
  txt2 <- tryCatch(if (!is.null(mc)) paste(deparse(mc), collapse = "") else "", error = function(e) "")
  s2 <- .normalize_sample(txt2); if (s2 != "unknown") return(s2)
  pf <- parent.frame()
  nms <- ls(envir = pf, all.names = TRUE)
  cand <- nms[grepl("adults|adolescents|children_parents|children|parents_p6|children_p6", tolower(nms))]
  for (nm in cand) { s3 <- .normalize_sample(nm); if (s3 != "unknown") return(s3) }
  "unknown"
}
.ensure_dir <- function(path, dry_run) if (!dir.exists(path) && !dry_run) dir.create(path, recursive = TRUE, showWarnings = FALSE)
.is_empty_df <- function(x) is.null(x) || nrow(x) == 0 || all(vapply(x, function(col) all(is.na(col)), logical(1)))
.parse_pid <- function(lbl) { s <- trimws(as.character(lbl)); d <- gsub("\\D+", "", s); if (nzchar(d)) d else "unknown" }

## Source required functions ---------------------------------------------------
source(file.path(function_path, "separate_by_project.R"))
source(file.path(function_path, "remove_test_rows.R"))
source(file.path(function_path, "copy_psytool_files.R"))
source(file.path(function_path, "extract_pilot_by_vpid.R"))
source(file.path(function_path, "resolve_duplicates.R"))
source(file.path(function_path, "correct_child_vpids.R"))
source(file.path(function_path, "check_vpid_forms.R"))
source(file.path(function_path, "find_pilot_ids.R"))
source(file.path(function_path, "compare_vpcodes.R"))
source(file.path(function_path, "partition_empty_obs_psytoolkit.R"))
source(file.path(function_path, "collect_ids_to_excel.R"))
source(file.path(function_path, "move_old_backbones.R"))
source(file.path(function_path, "setup_logging.R"))
source(file.path(function_path, "qc_ranges_and_missing.R"))
source(file.path(function_path, "aggregate_scales.R"))
source(file.path(function_path, "extract_scales.R"))
source(file.path(function_path, "prepare_project_slices.R"))
source(file.path(function_path, "write_project_slices.R"))
source(file.path(function_path, "analyze_rushing.R"))


## Move old Data ---------------------------------------------------------------
move_old_backbones(out_path, dry_run = FALSE)

## Setup Logging ---------------------------------------------------------------
logger <- setup_logging("logs/all_action_points.log")

## Backbone surveys ------------------------------------------------------------
file_adults            <- "results-survey564757_remids_translated.csv"
file_adolescents       <- "results-survey585676.csv"
file_children_parents  <- "results-survey798916_remids_translated.csv"
file_parents_p6        <- "results-survey191355.csv"
file_children_p6       <- "results-survey518972.csv"

## Load data -------------------------------------------------------------------
# Questionnaires
dat_adults           <- safe_read_csv(file.path(name, in_path, file_adults),           sep = ";")
dat_adolescents      <- safe_read_csv(file.path(name, in_path, file_adolescents),      sep = ";")
dat_children_parents <- safe_read_csv(file.path(name, in_path, file_children_parents), sep = ";")
dat_parents_p6       <- safe_read_csv(file.path(name, in_path, file_parents_p6),       sep = ";")
dat_children_p6      <- safe_read_csv(file.path(name, in_path, file_children_p6),      sep = ";")

# Get metadata
quest_info <- file.info(file.path(name, in_path, file_adults))
quest_info$sample <- "adults"
quest_info[2, ]   <- c(file.info(file.path(name, in_path, file_adolescents)),      "adolescents")
quest_info[3, ]   <- c(file.info(file.path(name, in_path, file_children_parents)), "children_parents")
quest_info[4, ]   <- c(file.info(file.path(name, in_path, file_parents_p6)),       "parents_p6")
quest_info[5, ] 